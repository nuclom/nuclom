---
title: 'AI Video Processing API'
description: 'Intelligent analysis including transcription, summarization, and code detection'
icon: 'brain'
---

The AI Services API provides intelligent analysis and processing capabilities for video content, including automatic transcription, summarization, code snippet detection, and chapter generation.

## Overview

Nuclom's AI integration leverages OpenAI Whisper for transcription and XAI Grok-3 for analysis to provide:

<CardGroup cols={2}>
  <Card title="Transcription" icon="microphone">
    Automatic video transcription with timestamps
  </Card>
  <Card title="Summarization" icon="file-lines">
    AI-powered video summarization
  </Card>
  <Card title="Action Items" icon="list-check">
    Action item extraction with priority levels
  </Card>
  <Card title="Code Detection" icon="code">
    Code snippet detection and formatting
  </Card>
  <Card title="Chapters" icon="bookmark">
    Chapter/key moment generation
  </Card>
  <Card title="Tagging" icon="tags">
    Intelligent tagging
  </Card>
</CardGroup>

## Video AI Processing Pipeline

When a video is uploaded, it goes through the following AI processing stages:

<Steps>
  <Step title="Pending">
    Video uploaded, waiting for processing
  </Step>
  <Step title="Transcribing">
    Audio is being transcribed using OpenAI Whisper
  </Step>
  <Step title="Analyzing">
    AI is generating summary, action items, tags, chapters, and code snippets
  </Step>
  <Step title="Completed">
    All AI processing finished successfully
  </Step>
</Steps>

<Warning>
  If processing fails, the status will be set to "Failed" and error details will be available in the response.
</Warning>

## Endpoints

### Trigger AI Processing

Manually trigger AI processing for a video.

<CodeGroup>

```bash Request
POST /api/videos/{videoId}/process
Authorization: Bearer <session_token>
```

```json Response
{
  "success": true,
  "data": {
    "message": "Video processing completed",
    "status": "completed",
    "summary": "AI-generated summary of the video content...",
    "tags": ["meeting", "planning", "Q1"],
    "actionItems": [
      {
        "text": "Complete user authentication implementation",
        "timestamp": 120,
        "priority": "high"
      }
    ],
    "chapters": 5,
    "codeSnippets": 2
  }
}
```

</CodeGroup>

### Get Processing Status

Check the current AI processing status of a video.

<CodeGroup>

```bash Request
GET /api/videos/{videoId}/process
```

```json Response
{
  "success": true,
  "data": {
    "videoId": "video_123",
    "status": "completed",
    "error": null,
    "hasTranscript": true,
    "hasSummary": true,
    "tags": ["meeting", "planning", "Q1"],
    "actionItems": [
      {
        "text": "Complete user authentication implementation",
        "timestamp": 120,
        "priority": "high"
      }
    ]
  }
}
```

</CodeGroup>

### Get Video Chapters

Retrieve AI-generated chapters for a video.

<CodeGroup>

```bash Request
GET /api/videos/{videoId}/chapters
```

```json Response
{
  "success": true,
  "data": {
    "videoId": "video_123",
    "chapters": [
      {
        "id": "chapter_1",
        "title": "Introduction",
        "summary": "Overview of the meeting agenda",
        "startTime": 0,
        "endTime": 120
      },
      {
        "id": "chapter_2",
        "title": "Q1 Planning Discussion",
        "summary": "Team discusses priorities for Q1",
        "startTime": 120,
        "endTime": 480
      }
    ],
    "count": 2
  }
}
```

</CodeGroup>

### Get Code Snippets

Retrieve AI-detected code snippets from video content.

<CodeGroup>

```bash Request
GET /api/videos/{videoId}/code-snippets
```

```json Response
{
  "success": true,
  "data": {
    "videoId": "video_123",
    "codeSnippets": [
      {
        "id": "snippet_1",
        "language": "javascript",
        "code": "const user = await auth.getUser();",
        "title": "User Authentication",
        "description": "Getting the authenticated user",
        "timestamp": 245
      },
      {
        "id": "snippet_2",
        "language": "bash",
        "code": "npm install @effect/platform",
        "title": "Package Installation",
        "description": "Installing Effect platform package",
        "timestamp": 380
      }
    ],
    "count": 2
  }
}
```

</CodeGroup>

## Data Models

### Processing Status

```typescript
type ProcessingStatus =
  | "pending"       // Waiting for processing
  | "transcribing"  // Transcribing audio
  | "analyzing"     // Running AI analysis
  | "completed"     // Processing finished
  | "failed";       // Processing failed
```

### Transcript Segment

```typescript
interface TranscriptSegment {
  startTime: number;  // Start time in seconds
  endTime: number;    // End time in seconds
  text: string;       // Transcribed text
  confidence?: number; // Confidence score (0-1)
}
```

### Action Item

```typescript
interface ActionItem {
  text: string;                          // Action item description
  timestamp?: number;                     // Timestamp in video (seconds)
  priority?: "high" | "medium" | "low";  // Priority level
}
```

### Chapter

```typescript
interface VideoChapter {
  id: string;
  videoId: string;
  title: string;
  summary?: string;
  startTime: number;  // Start time in seconds
  endTime?: number;   // End time in seconds
  createdAt: Date;
}
```

### Code Snippet

```typescript
interface VideoCodeSnippet {
  id: string;
  videoId: string;
  language?: string;    // Programming language
  code: string;         // The actual code
  title?: string;       // Title/description
  description?: string; // Detailed description
  timestamp?: number;   // Timestamp in video (seconds)
  createdAt: Date;
}
```

## Video Upload with AI Processing

When uploading a video, AI processing starts automatically.

<CodeGroup>

```bash Request
POST /api/videos/upload
Content-Type: multipart/form-data
```

```json Response
{
  "success": true,
  "data": {
    "videoId": "video_123",
    "videoUrl": "https://storage.example.com/videos/...",
    "thumbnailUrl": "https://storage.example.com/thumbnails/...",
    "duration": "10:30",
    "processingStatus": "pending"
  }
}
```

</CodeGroup>

### Form Data Parameters

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `video` | file | Yes | The video file |
| `title` | string | Yes | Video title |
| `description` | string | No | Video description |
| `organizationId` | string | Yes | Organization ID |
| `authorId` | string | Yes | Author user ID |
| `channelId` | string | No | Channel ID |
| `collectionId` | string | No | Collection ID |
| `skipAIProcessing` | boolean | No | Skip AI processing if true |

## Error Responses

<AccordionGroup>
  <Accordion title="Video Not Found (404)">
    ```json
    {
      "success": false,
      "error": "Video not found"
    }
    ```
  </Accordion>
  <Accordion title="Video URL Not Available (500)">
    ```json
    {
      "success": false,
      "error": "Video URL not available for processing"
    }
    ```
  </Accordion>
  <Accordion title="Transcription Service Not Configured (500)">
    ```json
    {
      "success": false,
      "error": "Transcription service not available. Please configure REPLICATE_API_TOKEN."
    }
    ```
  </Accordion>
  <Accordion title="Already Processing">
    ```json
    {
      "success": true,
      "data": {
        "message": "Video is already being processed",
        "status": "transcribing"
      }
    }
    ```
  </Accordion>
</AccordionGroup>

## Environment Configuration

Required environment variables for AI processing:

```bash
# Replicate API Token (for Whisper transcription)
REPLICATE_API_TOKEN=r8_...
```

<Note>
  The AI text generation (summaries, tags, action items) uses XAI Grok-3 via the Vercel AI SDK gateway and requires no additional configuration.
</Note>

## Architecture

### Services

The AI processing pipeline uses Effect-TS services:

| Service | Description |
|---------|-------------|
| **TranscriptionService** | Handles audio transcription via OpenAI Whisper |
| **AIService** | Provides AI analysis capabilities |
| **VideoAIProcessorService** | Orchestrates the full pipeline |

### AIService Methods

- `generateVideoSummary` - Generate video summary
- `generateVideoTags` - Generate relevant tags
- `extractActionItemsWithTimestamps` - Extract action items
- `detectCodeSnippets` - Detect code in speech
- `generateChapters` - Generate chapters/key moments

### Database Schema

```sql
-- Processing status added to videos table
ALTER TABLE videos ADD COLUMN processing_status TEXT DEFAULT 'pending';
ALTER TABLE videos ADD COLUMN processing_error TEXT;
ALTER TABLE videos ADD COLUMN transcript_segments JSONB;
ALTER TABLE videos ADD COLUMN ai_tags JSONB;
ALTER TABLE videos ADD COLUMN ai_action_items JSONB;

-- Chapters table
CREATE TABLE video_chapters (
  id TEXT PRIMARY KEY,
  video_id TEXT REFERENCES videos(id) ON DELETE CASCADE,
  title TEXT NOT NULL,
  summary TEXT,
  start_time INTEGER NOT NULL,
  end_time INTEGER,
  created_at TIMESTAMP DEFAULT NOW()
);

-- Code snippets table
CREATE TABLE video_code_snippets (
  id TEXT PRIMARY KEY,
  video_id TEXT REFERENCES videos(id) ON DELETE CASCADE,
  language TEXT,
  code TEXT NOT NULL,
  title TEXT,
  description TEXT,
  timestamp INTEGER,
  created_at TIMESTAMP DEFAULT NOW()
);
```

## Best Practices

<CardGroup cols={2}>
  <Card title="Video Quality" icon="video">
    Higher quality audio results in better transcription
  </Card>
  <Card title="Clear Speech" icon="microphone">
    Videos with clear speech produce more accurate transcripts
  </Card>
  <Card title="Background Noise" icon="volume-xmark">
    Minimize background noise for better results
  </Card>
  <Card title="Language" icon="language">
    Currently optimized for English content
  </Card>
</CardGroup>

## Limitations

<Warning>
  - Maximum video file size: 500MB
  - Transcription accuracy depends on audio quality
  - Code detection works best for clearly spoken code
  - Chapter generation requires sufficient content variation
</Warning>
